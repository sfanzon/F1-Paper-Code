[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Faster identification of faster Formula 1 drivers via time-rank duality",
    "section": "",
    "text": "This page contains the R code and data to reproduce the statistical analysis in the paper [1] named Faster identification of faster Formula 1 drivers via time-rank duality by John Fry, Tom Brighton and Silvio Fanzon.\nThe code should be simple to understand and comments are provided throughout. For a deeper understanding of the ranking model proposed, and the underlying statistical analysis, please refer to the paper [1].\nYou are free to use and modify the code in accordance with the license CC BY-NC 4.0. We kindly ask our work is credited by citing the paper [1]. You can download the BibTeX citation here."
  },
  {
    "objectID": "index.html#introduction",
    "href": "index.html#introduction",
    "title": "Faster identification of faster Formula 1 drivers via time-rank duality",
    "section": "",
    "text": "This page contains the R code and data to reproduce the statistical analysis in the paper [1] named Faster identification of faster Formula 1 drivers via time-rank duality by John Fry, Tom Brighton and Silvio Fanzon.\nThe code should be simple to understand and comments are provided throughout. For a deeper understanding of the ranking model proposed, and the underlying statistical analysis, please refer to the paper [1].\nYou are free to use and modify the code in accordance with the license CC BY-NC 4.0. We kindly ask our work is credited by citing the paper [1]. You can download the BibTeX citation here."
  },
  {
    "objectID": "index.html#the-data",
    "href": "index.html#the-data",
    "title": "Faster identification of faster Formula 1 drivers via time-rank duality",
    "section": "The data",
    "text": "The data\nData used for the statistical analysis in the paper [1] can be downloaded here. The latter contains placements of 20 drivers for the 22 races in the 2022 F1 Season plus 3 sprint races (Source)."
  },
  {
    "objectID": "index.html#the-r-code",
    "href": "index.html#the-r-code",
    "title": "Faster identification of faster Formula 1 drivers via time-rank duality",
    "section": "The R code",
    "text": "The R code\nThe annotated R code given below reproduces the statistical analysis in the paper [1]. The code is mix of R scripts and interactive R console work.\nThe code runs in R version 4.3.3 and above with no additional packages.\n\nCalibration with bookmakers’ odds\nThe first R function listed below is used to minimise the residual sum of squares between the implied probabilities obtained from bookmakers odds and the win probabilities written as a function of the lambda values. The input is a parameter of lambda values. The dimension of the input vector is the number of unique bookmakers odds. This is an important constraint that needs to be obeyed. Imposing this constraint also improves the speed and smoothness of the computation. The function is then run in conjunction with the optim command in R to perform the minimisation. Please see below.\n#input is the vector of win probabilities\n#output is the estimated lambda values\n\nlambdaest4 &lt;- function(x){\n\n  input &lt;- c(0.031655049, 0.031655049, 0.673389233, 0.063310099, \n             0.031655049, 0.028380389, 0.063310099, 0.048413605, \n             0.001642777, 0.001642777, 0.01016088, 0.001642777, \n             0.001642777, 0.001642777, 0.001642777, 0.001642777, \n             0.001642777, 0.001642777, 0.001642777, 0.001642777)\n\n  #given 7 input values\n\n  target&lt;-sort(input)\n  lambda&lt;-rep(c(x[1], x[2], x[3], x[4], x[5], x[6], x[7]), \n              rle(target)$lengths)\n\n  \n  pred &lt;- lambda / sum(lambda)\n  distance &lt;- sum( (target - pred )^2 )\n\n  return(distance)\n}\nx1\n[1] 0.0004205564 0.0026012171 0.0072654675 0.0081037902 0.0123940343\n[6] 0.0162075831 0.1723897481\n&gt; optim(x1, lambdaest4, control=list(maxit=10000))\n$par\n[1] 0.0004205564 0.0026012171 0.0072654675 0.0081037902 0.0123940343\n[6] 0.0162075831 0.1723897481\n\n\nRegression estimation\nThe regression analysis in the paper proceeds via stepwise regression. Useful background can be found in Fry and Burke [2]. However, in sharp contrast to the standard regression examples in Fry and Burke [2], a constraint is made so that all considered models have to include the driverorder2 dummy variable distinguishing between teams’ first and second drivers.\nThe following R code reads in the data on drivers placements found here. Then it assigns variables and then runs a set of stepwise, forwards and backwards regressions.\nf1seconddata &lt;- read.table(\"F:f1seconddata.txt\")\nposition &lt;- f1seconddata[ , -1]\npositionlabel &lt;- c(position[,1], position[,2], position[,3], \n                   position[,4], position[,5], position[,6], \n                   position[,7], position[,8], position[,9], \n                   position[,10], position[,11], position[,12], \n                   position[,13], position[,14], position[,15], \n                   position[,16], position[,17], position[,18], \n                   position[,19], position[,20], position[,21], \n                   position[,22], position[,23], position[,24], \n                   position[,25])\n\n#Parameterise in terms of first driver, second driver\ndriverorder &lt;- rep(c(1, 2), 10)\ndriverorder&lt; - rep(driverorder, 25)\n\n#Re-coded the driver dummy variable to lie between 0 and 1\ndriverorder2 &lt;- driverorder - 1\nconstructors &lt;- rep(c(\"Mercedes\", \"RedBull\", \"Ferrari\", \"Mclaren\", \n                      \"Alpine\", \"AstonMartin\", \"Haas\", \"AlfaTauri\", \n                      \"AlfaRomeo\", \"Williams\"), \n                      c(2, 2, 2, 2, 2, 2, 2, 2, 2, 2))\nconstructors &lt;- rep(constructors, 25)\n\nmercedesdummy &lt;- 1 * (constructors == \"Mercedes\")\nredbulldummy &lt;-1 * (constructors == \"RedBull\")\nferraridummy &lt;- 1 * (constructors == \"Ferrari\")\nmclarendummy &lt;- 1 * (constructors == \"Mclaren\")\nalpinedummy &lt;- 1 * (constructors == \"Alpine\")\nastonmartindummy &lt;- 1 * (constructors == \"AstonMartin\")\nhaasdummy &lt;- 1 * (constructors == \"Haas\")\nalfatauridummy &lt;- 1 * (constructors == \"AlfaTauri\")\nalfaromeodummy &lt;- 1 * (constructors == \"AlfaRomeo\")\n\nfull2.lm &lt;- lm(formula = positionlabel ~ driverorder2 + mercedesdummy\n               + redbulldummy + ferraridummy + mclarendummy \n               + alpinedummy + astonmartindummy + haasdummy \n               + alfatauridummy + alfaromeodummy)\n\nb.lm &lt;- lm(positionlabel ~ driverorder2)\n\n#Stepwise regression\nstep(b.lm, \n    scope = list(\n    lower = formula(b.lm), \n    upper = formula(full2.lm)), \n    direction = \"both\")\n\nstepwise.lm &lt;- lm(formula = positionlabel ~ driverorder2 + redbulldummy \n                  + mercedesdummy + ferraridummy + mclarendummy \n                  + alpinedummy + astonmartindummy)\n\n#Forward selection\nstep(b.lm, \n     scope = list(\n     lower = formula(b.lm), \n     upper = formula(full2.lm)), \n     direction = \"forward\")\n\nstepforward.lm &lt;- lm(formula = positionlabel ~ driverorder2 \n                     + redbulldummy + mercedesdummy + ferraridummy \n                     + mclarendummy + alpinedummy + astonmartindummy)\n\n#Backard selection\nstep(full2.lm, \n    scope = list(\n    lower = formula(b.lm), \n    upper = formula(full2.lm)), \n    direction = \"backward\")\n\nstepback.lm &lt;- lm(formula = positionlabel ~ driverorder2 \n                  + mercedesdummy + redbulldummy + ferraridummy \n                  + mclarendummy  + alpinedummy + astonmartindummy \n                  + haasdummy + alfatauridummy + alfaromeodummy)\nAt this juncture it becomes clear that forwards and stepwise regression choose the same model. Backwards regression leads to a model with additional variables in it. The following R code suggests that the larger model does not lead to a significant improvement over the smaller model chosen by stepwise regression.\nanova(stepwise.lm, stepback.lm, test = \"F\")\nAnalysis of Variance Table\n\nModel 1: positionlabel ~ driverorder2 + redbulldummy + mercedesdummy + \n    ferraridummy + mclarendummy + alpinedummy + astonmartindummy\nModel 2: positionlabel ~ driverorder2 + mercedesdummy + redbulldummy + \n    ferraridummy + mclarendummy + alpinedummy + astonmartindummy + \n    haasdummy + alfatauridummy + alfaromeodummy\n  Res.Df     RSS Df Sum of Sq      F  Pr(&gt;F)  \n1    492 10117.4                              \n2    489  9978.1  3     139.3 2.2756 0.07903 .\nThe following R code now presents the regression results presented in Table 3 of the paper.\nsummary(stepwise.lm)\nCall:\nlm(formula = positionlabel ~ driverorder2 + redbulldummy + mercedesdummy + \n    ferraridummy + mclarendummy + alpinedummy + astonmartindummy)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-9.058 -3.192 -1.058  2.517 15.592 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       13.8420     0.3794  36.484  &lt; 2e-16 ***\ndriverorder2       0.2160     0.4056   0.533   0.5946    \nredbulldummy      -9.6500     0.7170 -13.459  &lt; 2e-16 ***\nmercedesdummy     -8.2700     0.7170 -11.534  &lt; 2e-16 ***\nferraridummy      -7.6900     0.7170 -10.725  &lt; 2e-16 ***\nmclarendummy      -3.5500     0.7170  -4.951 1.02e-06 ***\nalpinedummy       -3.5500     0.7170  -4.951 1.02e-06 ***\nastonmartindummy  -1.7900     0.7170  -2.496   0.0129 *  \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 4.535 on 492 degrees of freedom\nMultiple R-squared:  0.3914,    Adjusted R-squared:  0.3828 \nF-statistic: 45.21 on 7 and 492 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "index.html#license-attribution",
    "href": "index.html#license-attribution",
    "title": "Faster identification of faster Formula 1 drivers via time-rank duality",
    "section": "License & Attribution",
    "text": "License & Attribution\n\nThis work is licensed under Creative Commons Attribution-NonCommercial 4.0 International License\n\n\n\n\nThis license enables reusers to distribute, remix, adapt, and build upon the material in any medium or format for noncommercial purposes only, and only so long as attribution is given to the creator. We kindly ask our work is credited by citing the paper [1] as shown below\n\nFry, John and Brighton, Tom and Fanzon, Silvio. Faster identification of faster Formula 1 drivers via time-rank duality, Preprint arXiv.2312.14637. (2024)\nhttps://doi.org/10.48550/arXiv.2312.14637\n\nBibTex citation: Download here or copy from box below\n@article{2024-Fry-Bri-Fan,\n  author = {Fry, John and Brighton, Tom and Fanzon, Silvio},\n  title = {Faster identification of faster Formula 1 drivers via \n           time-rank duality},\n  journal = {Preprint},\n  year = {2024},\n  doi = {10.48550/arXiv.2312.14637}\n}"
  }
]